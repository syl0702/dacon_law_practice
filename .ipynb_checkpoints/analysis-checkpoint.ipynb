{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c250b4ba-c368-4823-a2dc-abe0bc79079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a76ff7d-2abe-4a30-a14a-8c29362e843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data./train.csv')\n",
    "test_df = pd.read_csv('./data./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0204afd9-c593-4abc-8073-5e2d735a12eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2478, step=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b3aa49-221c-400b-ab2a-1c8f29e9e7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2478 entries, 0 to 2477\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   ID                  2478 non-null   object\n",
      " 1   first_party         2478 non-null   object\n",
      " 2   second_party        2478 non-null   object\n",
      " 3   facts               2478 non-null   object\n",
      " 4   first_party_winner  2478 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 96.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb595142-2391-4368-81b8-7e3cc144e0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2478.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.665456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.471926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_party_winner\n",
       "count         2478.000000\n",
       "mean             0.665456\n",
       "std              0.471926\n",
       "min              0.000000\n",
       "25%              0.000000\n",
       "50%              1.000000\n",
       "75%              1.000000\n",
       "max              1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cacfba3-ab3d-4cc9-bd6a-4fff420eb8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Stephen Duncan</td>\n",
       "      <td>Lawrence Owens</td>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID         first_party                    second_party  \\\n",
       "0  TRAIN_0000   Phil A. St. Amant              Herman A. Thompson   \n",
       "1  TRAIN_0001      Stephen Duncan                  Lawrence Owens   \n",
       "2  TRAIN_0002   Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
       "3  TRAIN_0003          Linkletter                          Walker   \n",
       "4  TRAIN_0004  William Earl Fikes                         Alabama   \n",
       "\n",
       "                                               facts  first_party_winner  \n",
       "0  On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n",
       "1  Ramon Nelson was riding his bike when he suffe...                   0  \n",
       "2  An Alabama state court convicted Billy Joe Mag...                   1  \n",
       "3  Victor Linkletter was convicted in state court...                   0  \n",
       "4  On April 24, 1953 in Selma, Alabama, an intrud...                   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13bb8ef-3aca-45e6-ba2c-03cfe82451f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On June 27, 1962, Phil St. Amant, a candidate for public office, made a television speech in Baton Rouge, Louisiana.  During this speech, St. Amant accused his political opponent of being a Communist and of being involved in criminal activities with the head of the local Teamsters Union.  Finally, St. Amant implicated Herman Thompson, an East Baton Rouge deputy sheriff, in a scheme to move money between the Teamsters Union and St. Amant’s political opponent. \\nThompson successfully sued St. Amant for defamation.  Louisiana’s First Circuit Court of Appeals reversed, holding that Thompson did not show St. Amant acted with “malice.”  Thompson then appealed to the Supreme Court of Louisiana.  That court held that, although public figures forfeit some of their First Amendment protection from defamation, St. Amant accused Thompson of a crime with utter disregard of whether the remarks were true.  Finally, that court held that the First Amendment protects uninhibited, robust debate, rather than an open season to shoot down the good name of anyone who happens to be a public servant. \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['facts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86bba959-59e1-4d30-bfa4-d987e0e66e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\navyb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\navyb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\navyb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\navyb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\navyb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\navyb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\navyb\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5f11b6-a3b2-4733-9381-ca3df1a4188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be8c036-29df-4bea-a9a2-43ab9b15bee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\navyb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbaa0931-5f3f-4eb3-8529-6a62271363c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346bd9ed-a069-4749-a692-5900c5e72d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\navyb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2f6e3c7-b888-46ea-a27b-f0e715e816b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "stop_words.extend(months)\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73054dd-0560-4a27-8113-3f2f64ffbc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\navyb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15baf60-6ae2-4c55-b233-6b6d7516f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    sents = list(word_tokenize(df.loc[i, 'facts']))\n",
    "    j = 0\n",
    "    texts = []\n",
    "    while j < len(sents)-1:\n",
    "        word = sents[j].lower()\n",
    "\n",
    "        if word not in stop_words:\n",
    "            if not word.isnumeric():\n",
    "                pos = wordnet.VERB\n",
    "                lemmatized_word = lemmatizer.lemmatize(word, pos)\n",
    "                texts.append(lemmatized_word)\n",
    "\n",
    "            j += 1\n",
    "        else:\n",
    "            j+=1\n",
    "        # if sents[j].lower() in stop_words:\n",
    "        #     sents.remove(sents[j])\n",
    "        # try:\n",
    "        #     int(sents[j])\n",
    "        #     sents.remove(sents[j])\n",
    "        # except ValueError:\n",
    "        #     word = sents[j].lower()\n",
    "        #     pos = wordnet.VERB\n",
    "        #      # texts = texts + ' ' + str(sents[j].lower())\n",
    "        #     lemmatized_word = lemmatizer.lemmatize(word, pos)\n",
    "        #     texts.append(lemmatized_word)\n",
    "        #     j += 1\n",
    "\n",
    "    lemmatized_txt = ' '.join(texts)\n",
    "    data.loc[i, 'facts'] = lemmatized_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f6f3bd5-1655-46e0-8bf2-1077db134949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ramon',\n",
       " 'Nelson',\n",
       " 'was',\n",
       " 'riding',\n",
       " 'his',\n",
       " 'bike',\n",
       " 'when',\n",
       " 'he',\n",
       " 'suffered',\n",
       " 'a',\n",
       " 'lethal',\n",
       " 'blow',\n",
       " 'to',\n",
       " 'the',\n",
       " 'back',\n",
       " 'of',\n",
       " 'his',\n",
       " 'head',\n",
       " 'with',\n",
       " 'a',\n",
       " 'baseball',\n",
       " 'bat',\n",
       " '.',\n",
       " 'After',\n",
       " 'two',\n",
       " 'eyewitnesses',\n",
       " 'identified',\n",
       " 'Lawrence',\n",
       " 'Owens',\n",
       " 'from',\n",
       " 'an',\n",
       " 'array',\n",
       " 'of',\n",
       " 'photos',\n",
       " 'and',\n",
       " 'then',\n",
       " 'a',\n",
       " 'lineup',\n",
       " ',',\n",
       " 'he',\n",
       " 'was',\n",
       " 'tried',\n",
       " 'and',\n",
       " 'convicted',\n",
       " 'for',\n",
       " 'Nelson',\n",
       " '’',\n",
       " 's',\n",
       " 'death',\n",
       " '.',\n",
       " 'Because',\n",
       " 'Nelson',\n",
       " 'was',\n",
       " 'carrying',\n",
       " 'cocaine',\n",
       " 'and',\n",
       " 'crack',\n",
       " 'cocaine',\n",
       " 'potentially',\n",
       " 'for',\n",
       " 'distribution',\n",
       " ',',\n",
       " 'the',\n",
       " 'judge',\n",
       " 'at',\n",
       " 'Owens',\n",
       " '’',\n",
       " 'bench',\n",
       " 'trial',\n",
       " 'ruled',\n",
       " 'that',\n",
       " 'Owens',\n",
       " 'was',\n",
       " 'probably',\n",
       " 'also',\n",
       " 'a',\n",
       " 'drug',\n",
       " 'dealer',\n",
       " 'and',\n",
       " 'was',\n",
       " 'trying',\n",
       " 'to',\n",
       " '“',\n",
       " 'knock',\n",
       " '[',\n",
       " 'Nelson',\n",
       " ']',\n",
       " 'off.',\n",
       " '”',\n",
       " 'Owens',\n",
       " 'was',\n",
       " 'found',\n",
       " 'guilty',\n",
       " 'of',\n",
       " 'first-degree',\n",
       " 'murder',\n",
       " 'and',\n",
       " 'sentenced',\n",
       " 'to',\n",
       " '25',\n",
       " 'years',\n",
       " 'in',\n",
       " 'prison',\n",
       " '.',\n",
       " 'Owens',\n",
       " 'filed',\n",
       " 'a',\n",
       " 'petition',\n",
       " 'for',\n",
       " 'a',\n",
       " 'writ',\n",
       " 'of',\n",
       " 'habeas',\n",
       " 'corpus',\n",
       " 'on',\n",
       " 'the',\n",
       " 'grounds',\n",
       " 'that',\n",
       " 'his',\n",
       " 'constitutional',\n",
       " 'right',\n",
       " 'to',\n",
       " 'due',\n",
       " 'process',\n",
       " 'was',\n",
       " 'violated',\n",
       " 'during',\n",
       " 'the',\n",
       " 'trial',\n",
       " '.',\n",
       " 'He',\n",
       " 'argued',\n",
       " 'that',\n",
       " 'the',\n",
       " 'eyewitness',\n",
       " 'identification',\n",
       " 'should',\n",
       " 'have',\n",
       " 'been',\n",
       " 'inadmissible',\n",
       " 'based',\n",
       " 'on',\n",
       " 'unreliability',\n",
       " 'and',\n",
       " 'that',\n",
       " 'the',\n",
       " 'judge',\n",
       " 'impermissibly',\n",
       " 'inferred',\n",
       " 'a',\n",
       " 'motive',\n",
       " 'when',\n",
       " 'a',\n",
       " 'motive',\n",
       " 'was',\n",
       " 'not',\n",
       " 'an',\n",
       " 'element',\n",
       " 'of',\n",
       " 'the',\n",
       " 'offense',\n",
       " '.',\n",
       " 'The',\n",
       " 'district',\n",
       " 'court',\n",
       " 'denied',\n",
       " 'the',\n",
       " 'writ',\n",
       " 'of',\n",
       " 'habeas',\n",
       " 'corpus',\n",
       " ',',\n",
       " 'and',\n",
       " 'Owens',\n",
       " 'appealed',\n",
       " '.',\n",
       " 'The',\n",
       " 'U.S.',\n",
       " 'Court',\n",
       " 'of',\n",
       " 'Appeals',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Seventh',\n",
       " 'Circuit',\n",
       " 'reversed',\n",
       " 'the',\n",
       " 'denial',\n",
       " 'and',\n",
       " 'held',\n",
       " 'that',\n",
       " 'the',\n",
       " 'trial',\n",
       " 'judge',\n",
       " '’',\n",
       " 's',\n",
       " 'inference',\n",
       " 'about',\n",
       " 'Owens',\n",
       " '’',\n",
       " 's',\n",
       " 'motive',\n",
       " 'violated',\n",
       " 'his',\n",
       " 'right',\n",
       " 'to',\n",
       " 'have',\n",
       " 'his',\n",
       " 'guilt',\n",
       " 'adjudicated',\n",
       " 'solely',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'evidence',\n",
       " 'presented',\n",
       " 'at',\n",
       " 'trial',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(df.loc[1, 'facts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14fef13c-c966-4fb3-9f7e-5178c1745d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ramon nelson rid bike suffer lethal blow back head baseball bat . two eyewitness identify lawrence owens array photos lineup , try convict nelson ’ death . nelson carry cocaine crack cocaine potentially distribution , judge owens ’ bench trial rule owens probably also drug dealer try “ knock [ nelson ] off. ” owens find guilty first-degree murder sentence years prison . owens file petition writ habeas corpus ground constitutional right due process violate trial . argue eyewitness identification inadmissible base unreliability judge impermissibly infer motive motive element offense . district court deny writ habeas corpus , owens appeal . u.s. court appeal seventh circuit reverse denial hold trial judge ’ inference owens ’ motive violate right guilt adjudicate solely base evidence present trial'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1, 'facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be60295b-c969-4490-ab24-1e6e5ab9d2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['herbert',\n",
       " 'markman',\n",
       " 'own',\n",
       " 'patent',\n",
       " 'a',\n",
       " 'system',\n",
       " 'track',\n",
       " 'clothe',\n",
       " 'the',\n",
       " 'dry-cleaning',\n",
       " 'process',\n",
       " 'use',\n",
       " 'keyboard',\n",
       " 'data',\n",
       " 'processor',\n",
       " 'generate',\n",
       " 'transaction',\n",
       " 'record',\n",
       " ',',\n",
       " 'include',\n",
       " 'bar',\n",
       " 'code',\n",
       " 'readable',\n",
       " 'optical',\n",
       " 'detectors',\n",
       " '.',\n",
       " 'accord',\n",
       " 'the',\n",
       " 'patent',\n",
       " \"'s\",\n",
       " 'claim',\n",
       " ',',\n",
       " 'portion',\n",
       " 'the',\n",
       " 'patent',\n",
       " 'document',\n",
       " 'define',\n",
       " 'patentee',\n",
       " \"'s\",\n",
       " 'right',\n",
       " ',',\n",
       " 'markman',\n",
       " \"'s\",\n",
       " 'product',\n",
       " '``',\n",
       " 'maintain',\n",
       " 'inventory',\n",
       " 'total',\n",
       " \"''\",\n",
       " '``',\n",
       " 'detect',\n",
       " 'localize',\n",
       " 'spurious',\n",
       " 'additions',\n",
       " 'inventory',\n",
       " '.',\n",
       " \"''\",\n",
       " 'westview',\n",
       " 'instrument',\n",
       " ',',\n",
       " 'inc.',\n",
       " \"'s\",\n",
       " 'product',\n",
       " 'also',\n",
       " 'use',\n",
       " 'keyboard',\n",
       " 'processor',\n",
       " 'list',\n",
       " 'dry-cleaning',\n",
       " 'charge',\n",
       " 'bar-coded',\n",
       " 'ticket',\n",
       " 'can',\n",
       " 'read',\n",
       " 'optical',\n",
       " 'detectors',\n",
       " '.',\n",
       " 'an',\n",
       " 'infringement',\n",
       " 'suit',\n",
       " ',',\n",
       " 'hear',\n",
       " 'expert',\n",
       " 'witness',\n",
       " 'testify',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'the',\n",
       " 'claim',\n",
       " \"'s\",\n",
       " 'language',\n",
       " ',',\n",
       " 'jury',\n",
       " 'find',\n",
       " 'westview',\n",
       " \"'s\",\n",
       " 'product',\n",
       " 'infringe',\n",
       " 'markman',\n",
       " \"'s\",\n",
       " 'patent',\n",
       " '.',\n",
       " 'however',\n",
       " ',',\n",
       " 'district',\n",
       " 'court',\n",
       " 'direct',\n",
       " 'verdict',\n",
       " 'westview',\n",
       " 'the',\n",
       " 'grind',\n",
       " 'its',\n",
       " 'device',\n",
       " 'unable',\n",
       " 'track',\n",
       " '``',\n",
       " 'inventory',\n",
       " \"''\",\n",
       " 'that',\n",
       " 'term',\n",
       " 'use',\n",
       " 'the',\n",
       " 'claim',\n",
       " '.',\n",
       " 'affirm',\n",
       " ',',\n",
       " 'court',\n",
       " 'appeal',\n",
       " 'hold',\n",
       " 'the',\n",
       " 'interpretation',\n",
       " 'claim',\n",
       " 'term',\n",
       " 'the',\n",
       " 'exclusive',\n",
       " 'province',\n",
       " 'the',\n",
       " 'court',\n",
       " 'that',\n",
       " 'seventh',\n",
       " 'amendment',\n",
       " 'right',\n",
       " 'a',\n",
       " 'jury',\n",
       " 'trial',\n",
       " 'consistent',\n",
       " 'that',\n",
       " 'conclusion',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f59b227a-e20c-4b49-8060-653d425edac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stemmed_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstemmed_txt\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stemmed_txt' is not defined"
     ]
    }
   ],
   "source": [
    "stemmed_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1adf60c-2455-409f-878d-e5431592daff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"herbert markman own patent a system track clothe the dry-cleaning process use keyboard data processor generate transaction record , include bar code readable optical detectors . accord the patent 's claim , portion the patent document define patentee 's right , markman 's product `` maintain inventory total '' `` detect localize spurious additions inventory . '' westview instrument , inc. 's product also use keyboard processor list dry-cleaning charge bar-coded ticket can read optical detectors . an infringement suit , hear expert witness testify the mean the claim 's language , jury find westview 's product infringe markman 's patent . however , district court direct verdict westview the grind its device unable track `` inventory '' that term use the claim . affirm , court appeal hold the interpretation claim term the exclusive province the court that seventh amendment right a jury trial consistent that conclusion .\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "257445ec-afed-40c9-9ba0-e80cb06a4e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , phil st. amant , candidate public office , make television speech baton rouge , louisiana . speech , st. amant accuse political opponent communist involve criminal activities head local teamsters union . finally , st. amant implicate herman thompson , east baton rouge deputy sheriff , scheme move money teamsters union st. amant ’ political opponent . thompson successfully sue st. amant defamation . louisiana ’ first circuit court appeal reverse , hold thompson show st. amant act “ malice. ” thompson appeal supreme court louisiana . court hold , although public figure forfeit first amendment protection defamation , st. amant accuse thompson crime utter disregard whether remark true . finally , court hold first amendment protect uninhibited , robust debate , rather open season shoot good name anyone happen public servant'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0, 'facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb298b1-a8c0-4747-854d-16dc84fdcd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ramon nelson rid bike suffer lethal blow back head baseball bat . two eyewitness identify lawrence owens array photos lineup , try convict nelson ’ death . nelson carry cocaine crack cocaine potentially distribution , judge owens ’ bench trial rule owens probably also drug dealer try “ knock [ nelson ] off. ” owens find guilty first-degree murder sentence years prison . owens file petition writ habeas corpus ground constitutional right due process violate trial . argue eyewitness identification inadmissible base unreliability judge impermissibly infer motive motive element offense . district court deny writ habeas corpus , owens appeal . u.s. court appeal seventh circuit reverse denial hold trial judge ’ inference owens ’ motive violate right guilt adjudicate solely base evidence present trial'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1, 'facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a54ead3a-864d-4ec2-b017-d1c137f5d3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alabama state court convict billy joe magwood murder sentence death . subsequently , alabama federal district court partially grant mr. magwood 's petition federal habeas corpus relief . court uphold conviction instruct state court look mitigate evidence resentencing mr. magwood . upon resentencing , state court sentence mr. magwood death . mr. magwood file second petition federal habeas corpus relief federal district court argue judicial rule retroactively apply case lack effective counsel sentence . district court grant petition vacate mr. magwood 's death sentence . appeal , u.s. court appeal eleventh circuit reverse , hold prisoners raise challenge original sentence could raise earlier petition . court also hold mr. magwood 's counsel ineffective fail raise argument already decide state 's highest court adverse client 's position\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[2, 'facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9353a7c4-2766-48ba-bec9-b67b09ecf467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, , phil st. amant , candidate public office ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ramon nelson rid bike suffer lethal blow back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alabama state court convict billy joe magwood ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>victor linkletter convict state court evidence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>, selma , alabama , intruder break apartment d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               facts\n",
       "0  , , phil st. amant , candidate public office ,...\n",
       "1  ramon nelson rid bike suffer lethal blow back ...\n",
       "2  alabama state court convict billy joe magwood ...\n",
       "3  victor linkletter convict state court evidence...\n",
       "4  , selma , alabama , intruder break apartment d..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e57e0ec-9cd3-4544-8743-d10f1819fcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, , phil st. amant , candidate public office ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ramon nelson rid bike suffer lethal blow back ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alabama state court convict billy joe magwood ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>victor linkletter convict state court evidence...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>, selma , alabama , intruder break apartment d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>congress amend clean air act energy policy act...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>alliance bond fund , inc. , investment fund , ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>, district court sentence manuel d. peguero mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>, , enrico st. cyr , lawful permanent resident...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>herbert markman own patent system track clothe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  facts  first_party_winner\n",
       "0     , , phil st. amant , candidate public office ,...                   1\n",
       "1     ramon nelson rid bike suffer lethal blow back ...                   0\n",
       "2     alabama state court convict billy joe magwood ...                   1\n",
       "3     victor linkletter convict state court evidence...                   0\n",
       "4     , selma , alabama , intruder break apartment d...                   1\n",
       "...                                                 ...                 ...\n",
       "2473  congress amend clean air act energy policy act...                   1\n",
       "2474  alliance bond fund , inc. , investment fund , ...                   1\n",
       "2475  , district court sentence manuel d. peguero mo...                   0\n",
       "2476  , , enrico st. cyr , lawful permanent resident...                   0\n",
       "2477  herbert markman own patent system track clothe...                   0\n",
       "\n",
       "[2478 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([data['facts'], df['first_party_winner']], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0778f61-3487-4bec-bd32-e75b11afb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = final_df['facts']\n",
    "# target = final_df['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c40fdb48-5c93-40f3-af5c-580f52f0ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "encoded_facts = tfidf_vect.fit_transform(final_df['facts'])\n",
    "encoded_df = pd.DataFrame(encoded_facts, columns=['facts_cal'])\n",
    "\n",
    "finals_df = pd.concat([encoded_df, final_df.drop(['facts'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c047b907-81bd-45b5-83e7-127ff61a04e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              facts_cal  first_party_winner  \\\n",
      "0       (0, 11727)\\t0.07989989646339221\\n  (0, 5948)...                   1   \n",
      "1       (0, 10172)\\t0.04744568808437846\\n  (0, 4771)...                   0   \n",
      "2       (0, 10021)\\t0.05886843061250726\\n  (0, 2639)...                   1   \n",
      "3       (0, 11112)\\t0.1669649800607266\\n  (0, 13578)...                   0   \n",
      "4       (0, 653)\\t0.02719926789988724\\n  (0, 7189)\\t...                   1   \n",
      "...                                                 ...                 ...   \n",
      "2473    (0, 13428)\\t0.13220070322333363\\n  (0, 10794...                   1   \n",
      "2474    (0, 6744)\\t0.10114120487237467\\n  (0, 5658)\\...                   1   \n",
      "2475    (0, 9689)\\t0.7657908434803934\\n  (0, 8021)\\t...                   0   \n",
      "2476    (0, 3426)\\t0.44245654448281035\\n  (0, 4569)\\...                   0   \n",
      "2477    (0, 10385)\\t0.10701961225799636\\n  (0, 2686)...                   0   \n",
      "\n",
      "                                                      0  \n",
      "0       (0, 11727)\\t0.07989989646339221\\n  (0, 5948)...  \n",
      "1       (0, 10172)\\t0.04744568808437846\\n  (0, 4771)...  \n",
      "2       (0, 10021)\\t0.05886843061250726\\n  (0, 2639)...  \n",
      "3       (0, 11112)\\t0.1669649800607266\\n  (0, 13578)...  \n",
      "4       (0, 653)\\t0.02719926789988724\\n  (0, 7189)\\t...  \n",
      "...                                                 ...  \n",
      "2473    (0, 13428)\\t0.13220070322333363\\n  (0, 10794...  \n",
      "2474    (0, 6744)\\t0.10114120487237467\\n  (0, 5658)\\...  \n",
      "2475    (0, 9689)\\t0.7657908434803934\\n  (0, 8021)\\t...  \n",
      "2476    (0, 3426)\\t0.44245654448281035\\n  (0, 4569)\\...  \n",
      "2477    (0, 10385)\\t0.10701961225799636\\n  (0, 2686)...  \n",
      "\n",
      "[2478 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(finals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34e0aca1-96ad-40e2-90bf-c38abf85eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = finals_df['facts_cal']\n",
    "target = finals_df['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b64f8ef2-978b-4f1b-bf3c-52eabb970cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0958517d-e45c-403d-8bad-7756a27c8c21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'csr_matrix'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      3\u001b[0m lr1 \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mlr1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1208\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1206\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1208\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1216\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:917\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    916\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m--> 917\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    919\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr1 = LogisticRegression(max_iter=10000)\n",
    "lr1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1e92f67-03a5-42af-bc1c-fd4653b00b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6639784946236559"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict = lr1.predict(x_test)\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4cd0ad0-4560-40ab-bd04-c4a000492c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>, , phil st. amant , candidate public office ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    facts\n",
       "count                                                2478\n",
       "unique                                               2478\n",
       "top     , , phil st. amant , candidate public office ,...\n",
       "freq                                                    1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a02a478-c4a7-417f-8b8b-de40165ab14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2478.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.665456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.471926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_party_winner\n",
       "count         2478.000000\n",
       "mean             0.665456\n",
       "std              0.471926\n",
       "min              0.000000\n",
       "25%              0.000000\n",
       "50%              1.000000\n",
       "75%              1.000000\n",
       "max              1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742dbcd0-dd8a-4e36-b8d8-b31b11412802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
